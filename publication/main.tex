% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
\usepackage[vlined,algoruled,linesnumbered]{algorithm2e}
\usepackage{amsmath,amssymb,nccmath,mathtools}
\usepackage{tabularx}
\usepackage{siunitx}
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
\usepackage{xcolor}
\renewcommand\UrlFont{\color{blue}\rmfamily}
\urlstyle{rm}
%
\begin{document}
%
\title{Masked Computation of the Floor Function and Its Application to the FALCON Signature}
%
\titlerunning{Masked Floor Function For FALCON}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Justine Paillet\inst{1,3}\orcidID{0009-0009-6056-7766} \and
  Pierre-Augustin Berthet\inst{2,3}\orcidID{0009-0005-5065-2730} \and
C\'edric Tavernier\inst{3}\orcidID{0009-0007-5224-492X}}
%
\authorrunning{J Paillet et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{
  Université Jean-Monnet, Saint-\'Etienne, France, \email{justine.paillet@univ-st-etienne.fr}
  \and
  Télécom Paris, Palaiseau, France, \email{berthet@telecom-paris.fr}
  \and
  Hensoldt SAS FRANCE, Plaisir, France, \email{<pierre-augustin.berthet,justine.paillet,cedric.tavernier>@hensoldt.net}
}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
With the ongoing standardization of new Post Quantum Cryptography (PQC) primitives by the National Institute of Standards and Technology (NIST), it is important to investigate the robustness of new designs to Side Channel Analysis (SCA). Amongst those future standards is Falcon, a lattice-based signature which relies of rational numbers. It thus requires an implementation using floating point arithmetic, which is harder to design well and secure. While recent work proposed a solution to mask the addition and the multiplication, some roadblocks remains, most noticeably how to protect the floor function. In this work we propose several methods to protect the computation of the floor function. We provide mathematical proofs of our methods as well as formal security proof in the probing model using the Non-Interference concepts. We also discuss their application to the FALCON Signature.

\keywords{Floor Function \and Floating-Point Arithmetic \and Post-Quantum Cryptography \and FALCON \and Side-Channel Analysis \and Masking}
\end{abstract}
%
%
%
\section{Introduction}
With the rise of quantum computing, mathematical problems which were hard to solve with current technologies will be easier to breach. Amongst the concerned problem is the Discrete Logarithm Problem (DLP) which can be solved in polynomial times by the Shor quantum algorithm \cite{doi:10.1137/S0036144598347011}. As much of the current asymmetric primitives rely on this problem and will be breach, new cryptographic primitves are studied. The National Institute of Standards and Technology (NIST) launched a post-quantum standardization process \cite{chen2016report}. The finalists are CRYSTALS Kyber \cite{8406610,nistfips203mlkem}, CRYSTALS Dilithium \cite{Ducas_Kiltz_Lepoint_Lyubashevsky_Schwabe_Seiler_Stehlé_2018,nistfips204mldsa}, SPHINCS+ \cite{10.1145/3319535.3363229,nistfips205shdsa} and FALCON \cite{prest2020falcon}.

\medskip

\noindent Another concern for the security of cryptographic primitives is their robustness to a Side-Channel opponent. Side-Channel Analysis (SCA) was first introduced by Paul Kocher \cite{10.1007/3-540-68697-5_9} in the mid-1990. This new branch of cryptanalysis focuses on studying the impact of a cryptosystem on its surroundings. AS computations take time and energy, an opponent able of accessing the variation of one or both could find correlations between its physical observations and the data manipulated, thus resulting in a leakage and a security breach. Thus, the study of weaknesses in implementations of new primitives and the ways to protect them is an active field of research.

\medskip 

\noindent While they have been many works focusing on CRYSTALS Dilithium and CRYSTALS Kyber, summed up by Ravi et al. \cite{10.1145/3603170}, FALCON is noticeably harder to protect. Indeed, the algorithm relies on floating-point arithmetic, for which there is little litterature on how to protect it.
%
\subsubsection{Related Work} Previous works have identified two main weaknesses within the signing process of Falcon : the pre-image computation and the Gaussian sampler. The pre-image computation was proved vulnerable by Karabulut and Aysu \cite{9586131} using an ElectroMagnetic (EM) attack. Their work was later improved by Guerreau et al. \cite{Guerreau_Martinelli_Ricosset_Rossi_2022}. To counter those attacks, Chen and Chen \cite{Chen_Chen_2024} propose a masked implementation of the addition and multiplication of FALCON. However, they did not delved into the second weakness of Falcon, the Gaussian sampler.\newline
The Gaussian sampler is vulnerable to timing attacks, as shown by previous work \cite{10.1007/978-3-662-53140-2_16,10.1145/3133956.3134028,cryptoeprint:2019/478,10.1145/3133956.3134023}. A isochronous design was proposed by Howe et al. \cite{10.1007/978-3-030-44223-1_4}. However, a successful single power analysis (SPA) was proposed by Guerreau et al. \cite{Guerreau_Martinelli_Ricosset_Rossi_2022} and further improved by Zhang et al. \cite{10.1007/978-3-031-30634-1_19}. There is currently no masking countermeasure for FALCON's Gaussian Sampler. Existing work \cite{10.1007/978-3-031-07082-2_9} tends to re-write the Gaussian Sampler to remove the use of floating arithmetic, thus avoiding the challenge of masking the floor function. 
%
\subsubsection{Our Contribution}
In this work we further expand the countermeasure from Chen and Chen \cite{Chen_Chen_2024} and apply it to the Gaussian Sampler. We propose a masking method based on the mantissa truncation to compute the floor function. We also propose a generic method to arithmetize the computation of the floor function. We discuss the application of both methods to masking FALCON.

\medskip

Relying on the previous work of Chen and Chen \cite{Chen_Chen_2024}, we also verify the higher-order security of our method in the probing model. Our formal proofs rely on the Non-Interference (NI) security model first introduced by Barthe et al. \cite{10.1145/2976749.2978427}.

\medskip

Finally, we provide some performances of our methods and compare them with the reference unmasked implementation and the previous work of Chen and Chen \cite{Chen_Chen_2024}. The implementation is tested on a personal computer with an Intel-Core i7-11850H CPU.
%
\section{Notation and Background}\label{sec:background}
\subsection{Notation}
\begin{itemize}
  \item We denote by $\mathbb{R}\backsim \mathbb{Z}$ any real number which is not an integer. For $x\in\mathbb{R}$, we denote the floor function of $x$ by $\lfloor x \rfloor$.
  \item We will use the dot $.$ as the separator between the integer part $i$ and the fractional part $f$ of a real number $x=i.f$.
  \item We denote the floor function of $x$ with $n$ decimals of absolute precision by $\lfloor x \rfloor_n$. Absolute precision implies $\lfloor x\rfloor_n = \lfloor x \rfloor + 0.\{0\}^n\|[0;9]^*$. This also implies that $0 \leq \lfloor x \rfloor_n - \lfloor x \rfloor < 1\times 10^{-n}$.
  \item We denote the floor function of $x$ with $n$ decimals of relative precision $\alpha\in[\num{0.1};1)$ by $\lfloor x \rfloor_n^\alpha$. Relative precision implies $-\alpha\times 10^{-n} < \lfloor x \rfloor_n^\alpha - \lfloor x \rfloor < \alpha\times 10^{-n}$.
  \item Let $a,b\in\mathbb{R}^2$. Let $k\in\mathbb{N}$. We say that $a\equiv_k b$ if $\lfloor a\rfloor = \lfloor b \rfloor$ and they have the same number of $0$ at least for the first $k$ decimals: $\lfloor a \rfloor + 0.\{0\}^k\|[0;9]^*$. For instance, $\num{4.05} \equiv_k \num{4.09}$ at precisions $k=0$ and $k=1$ but not at precision $k=2$.
\end{itemize}
% 
\subsection{FALCON Sign}
FALCON \cite{prest2020falcon} is a Lattice-Based signature using the GPV framework over the NTRU problem. In this paper we will focus on the Gaussian Sampler used in the signature algorithm. For more details on the key generation or the verification, please refer to the reference paper \cite{prest2020falcon}.

\subsubsection{Signature} The signature follows the Hash-Then-Sign strategy. The message $m$ is salted with a random value $r$ and then hashed into a challenge $c$. The remainder of the signature aims at building an instance of the SIS problem upon $c$ and a public key $h$, \emph{id est} finding $\vec{s} =(s_1,s_2)$ such as $s_1 + s_2 h = c$. To do so, the need to compute $\vec{s} = (\vec{t}-\vec{z})\mathbf{B}$, with $\vec{t}$ a pre-image vector and $\vec{z}$ provided by a Gaussian Sampler. Chen and Chen \cite{Chen_Chen_2024} focuses on masking the pre-image vector computation. In this work we intend to mask the Gaussian Sampler. The signature algorithm is detailled in Algorithm \ref{alg:falconsign}:

\begin{algorithm}[H]
  \caption{FALCON Sign \cite{prest2020falcon}}
  \label{alg:falconsign}
\end{algorithm}

\subsubsection{Gaussian Sampler}


\subsection{Floor Function}\label{subsec:floorfunction}
The floor function is defined as follows:
\begin{definition}\label{def:floorfunction}
  $\forall x \in \mathbb{R}$, the floor function of $x$, denoted by $\lfloor x \rfloor$, returns the greatest integer $z$ such as $z\leq x$.
\end{definition}
There are several ways of computing the floor function. The first one relies on floating-point arithmetic. A floating-point is composed of a sign bit, exponent bits and a mantissa \cite{kahan1996ieee}. Computing the floor function on a floating-point is performed by truncating the mantissa according to the value of the exponent and of the sign. However, while this method is fast and efficient, it requires the use of the exponent and the sign. In this work we will present a method to perform this truncation in a secure manner.

\medskip

\noindent Another way of computing the floor function is to use its associated Fourier series:\begin{equation}\label{eq:floorfourier}
  \forall x \in \mathbb{R}\backsim \mathbb{Z}, \lfloor x\rfloor = x - \frac{1}{2} + \frac{1}{\pi}\sum_{k=1}^n \frac{sin(2\pi kx)}{k},\text{ with }n\rightarrow \infty
\end{equation}
However, due to its discontinuities, Equation \ref{eq:floorfourier} suffers from the Gibbs phenomenon \cite{8e44e918-40ae-3857-bb25-dc12ccf9e7c3}, as illustrated in Figure \ref{fig:gibbs}. 
\begin{figure}[!h]
  \includegraphics[width=\textwidth]{figure/gibbsphenomenon.png}
  \label{fig:gibbs}
  \caption{Gibbs phenomenon for Equation \ref{eq:floorfourier} with $n=$\textcolor{red}{5},\textcolor{blue}{10},\textcolor{green}{50} and floor(x) in black}
\end{figure}
It means this series cannot be used as it is to mask the floor function in reasonable time. Indeed, we extrapolate through empirical observations that we would require $n=\num{2.5}\times 10^{13}$ to have at least one decimal of absolute precision on the floor computation of $1\times 10^{-16}$. Nonetheless, we will see in this work how we can adapt this Fourier series to compute the floor function in a secure way and in reasonable time with the required precision.
\subsection{Masking}

\section{Masking of the Floor Function}\label{sec:maskfloor}
\subsection{Arithmetization method}
The floor function can be arithmetized using Equation \ref{eq:floorfourier}. However, as stated in Section \ref{subsec:floorfunction}, this method cannot be performed in reasonable time. We thus elaborate a strategy to optimize this arithmetization.

\subsubsection{Absolute Precision} 
The first idea relies on constructing the floor of $x\in\mathbb{R}$ rather than computing it. Indeed, if we can compute the floor of $x$ with one decimal of precision, we can then multiply the result by $10$ and then reapply our computation to the new value $y=10\times \lfloor x\rfloor_1$. Thus, we have the following proposition:
\begin{proposition}\label{prop:floorprec}
  Let $x\in\mathbb{R}$. Let $y = 10\times\lfloor x\rfloor_1$. Then $\lfloor y \rfloor_1 /10 \equiv_2 \lfloor x \rfloor_2$.
\end{proposition}
\begin{proof}
  Let recall that $\lfloor x \rfloor_1 = \lfloor x \rfloor + 0.0 \|[0;9]^*$. Thus, $y=10\times\lfloor x \rfloor_1=\lfloor x\rfloor\|0+0.[0;9]^*$ as multiplying by $10$ can be seen as a left-shift in base $10$. By computing the floor of $y$ with absolute precision $1$ we have $y_1=\lfloor y \rfloor_1 = \lfloor x \rfloor\|0 + 0.0\|[0;9]^*$. Finally, $ y_1/10 = \lfloor x \rfloor + 0.00\|[0;9]^*\equiv_2 \lfloor x \rfloor_2$ as dividing by $10$ can be seen as a right-shift in base $10$.  
\end{proof}
Thus, we can use Proposition \ref{prop:floorprec} to construct the floor of $x$ with the following Algorithm \ref{alg:floorconstruct}:

\begin{algorithm}[H]
  \caption{ConstructFloor($x,prec$)}
  \label{alg:floorconstruct}
  \KwData{$x\in\mathbb{R}$ and the precision $prec\in\mathbb{N}$}
  \KwResult{$\lfloor x\rfloor_{prec}$}
  \For{\texttt{i from 0 to prec-1}}{
    $y \leftarrow \lfloor x \rfloor_1$\;
    $x \leftarrow 10\times y$\;}
    \Return{$x\times 10^{-prec}$}
\end{algorithm}

\begin{theorem}\label{thm:floorprec}
  Let $x\in\mathbb{R}$. Algorithm \ref{alg:floorconstruct} returns $\lfloor x \rfloor_{prec}$ for precision $prec$.
\end{theorem}
\begin{proof}
  We use a recursive proof. The initial state is proven by Proposition \ref{prop:floorprec}. Let Theorem \ref{thm:floorprec} be true for precision $prec-1$. We have $X=\lfloor x \rfloor_{prec-1}$ the output of Algorithm \ref{alg:floorconstruct}. We reapply Algorithm \ref{alg:floorconstruct} to $X\times 10^{prec-1}$ but with precision $1$ and then divide by $10^{prec-1}$. This is stricly equal to applying Algorithm \ref{alg:floorconstruct} with precision $prec$. Algorithm \ref{alg:floorconstruct} with precision $1$ is proven by Proposition \ref{prop:floorprec}. Thus, we have $\lfloor X \rfloor_1 = \lfloor x\rfloor \| \{0\}^{prec-1} + 0.0\|[0;9]^*$. By dividing by $10^{prec-1}$, we shift all the zeros stored in the integer part of $X$ into the fractional part. Thus we have $\lfloor X \rfloor_1 /10^{prec-1} = \lfloor x \rfloor + 0.\{0\}^{prec}\|[0;9]^* \equiv_{prec} \lfloor x \rfloor_{prec}$. We thus proved Theorem \ref{thm:floorprec}.
\end{proof}

%All we need now is a function able of computing $\lfloor x \rfloor_1$ in reasonable time. 
\subsubsection{Relative Precision}
We discuss how to achieve absolute precision from relative precision. In relative precision, we have the possibility that the error from the result can be negative. This results in $\lfloor x \rfloor_n^\alpha = \lfloor x \rfloor - 0.\{0\}^{n}\|[0;9]^*=\lfloor x \rfloor-1 + 0.\{9\}^{n}\|[0;9]^* $. Thus, we cannot construct the floor function using directly $\lfloor x \rfloor_n^\alpha$, as in Algorithm \ref{alg:floorconstruct}. We introduce a second idea: controlled bias.

\medskip

\noindent We have the following Proposition \ref{prop:floorbias}:
\begin{proposition}\label{prop:floorbias}
  Let $x\in\mathbb{R}$. Then $\lfloor x\rfloor_1 \equiv_1 \lfloor x \rfloor_2^\alpha + \alpha\times10^{-2}$.
\end{proposition}
\begin{proof}
  We have two cases to cover: \begin{enumerate}
    \item The error is negative. Thus $-\alpha\times 10^{-2} < \lfloor x \rfloor_2^\alpha - \lfloor x \rfloor \leq 0$ and $0 < \lfloor x \rfloor_2^\alpha + \alpha\times 10^{-2} - \lfloor x \rfloor \leq \alpha\times 10^{-2} < 1\times 10^{-2}$. Thus, in this case, we have $\lfloor x \rfloor_2^\alpha + \alpha\times 10^{-2} \equiv_2 \lfloor x \rfloor_2$ and by construction of $\lfloor x \rfloor_n$, we have $\lfloor x \rfloor_2^\alpha + \alpha\times 10^{-2} \equiv_1 \lfloor x \rfloor_1$.
    \item The error is positive. Thus $0 \leq \lfloor x \rfloor_2^\alpha - \lfloor x \rfloor < \alpha\times10^{-2}$ and $\alpha\times10^{-2} \leq \lfloor x \rfloor_2^\alpha + \alpha\times 10^{-2} - \lfloor x \rfloor \leq 2\alpha\times 10^{-2}$. This implies $0<\lfloor x \rfloor_2^\alpha + \alpha\times 10^{-2} - \lfloor x \rfloor<1\times10^{-1}$. Thus, in this case, we have $\lfloor x \rfloor_2^\alpha + \alpha\times 10^{-2} \equiv_1 \lfloor x \rfloor_1$.
  \end{enumerate}
  We demonstrate that we can have an absolute precision of $1$ from a relative precision of $2$.
\end{proof}

However, we can improve upon Proposition \ref{prop:floorbias} by limiting the maximum value of $\alpha$. We have the following proposition:\begin{proposition}\label{prop:floorbiasopt}
  Let $x\in\mathbb{R}$ and $\alpha<\num{0.5}$. Then $\lfloor x\rfloor_1 \equiv_1 \lfloor x \rfloor_1^\alpha + \alpha\times10^{-1}$.
\end{proposition}
\begin{proof}
  We have already proven in Proposition \ref{prop:floorbias} that for the negative bias, $\lfloor x \rfloor_1^\alpha + \alpha\times 10^{-1} - \lfloor x \rfloor \leq \alpha\times 10^{-1}$. As $\alpha<0.5$, we have $\lfloor x \rfloor_1 \equiv_1 \lfloor x \rfloor_1^\alpha$. For the postive bias, according to Proposition \ref{prop:floorbias} we have $\alpha\times10^{-1} \leq \lfloor x \rfloor_1^\alpha + \alpha\times 10^{-1} - \lfloor x \rfloor \leq 2\alpha\times 10^{-1}$. As $\alpha<\num{0.5}$, $2\alpha\times 10^{-1}<1\times 10^{-1}$. We have $\lfloor x \rfloor_1 \equiv_1 \lfloor x \rfloor_1^\alpha$.
\end{proof}

\subsubsection{Fourier Series}
We now need a way of computing the floor function with a relative precision of at least $2$ in reasonable time. Our final idea revolves around aborting Equation \ref{eq:floorfourier} early for a small value of $n$. Then, we reapply Equation \ref{eq:floorfourier} on the new value, with a small twist:

\begin{algorithm}[H]
  \caption{ArFloorStep($x,n,iter$)}
  \label{alg:floorstep1}
  \KwData{$x\in\mathbb{R}\backsim\mathbb{Z}$, the series limiter $n\in\mathbb{N}$ and the number of iterations $iter\in\mathbb{N}$}
  \KwResult{$\lfloor x \rfloor_2^\alpha+\frac{1}{2}$}
  \For{\texttt{i from 0 to iter-1}}{
    $x \leftarrow x + \frac{1}{\pi}\sum_{k=1}^{n}\frac{sin(2\pi k x)}{k}$\;
  }
  \Return{$x$}
\end{algorithm}
Instead of computing the floor function, Algorithm \ref{alg:floorstep1} gives the floor function with a positive bias of $\frac{1}{2}$. Indeed, applying Equation \ref{eq:floorfourier} and aborting without this bias does not unsure correctness. For instance, for a value close to $0$, using Equation \ref{eq:floorfourier} with a small $n$ results in $-\frac{1}{2} + e$, with $e$ small. Reapplying Equation \ref{eq:floorfourier} will give $-\frac{1}{2}+e-\frac{1}{2}+e_2 \approx -1$ as a result, which is not correct. Thus, it is important to remove $-\frac{1}{2}$ and only apply it after the successive early aborts and reapplications. As an example, Algorithm \ref{alg:floorstep1} is proven by Theorem \ref{thm:floorstep1} for a specific set of parameters:

\begin{theorem}\label{thm:floorstep1}
  Let $x\in(0;1)\subset\mathbb{R}\backsim \mathbb{Z}$ with up to $19$ decimals, \emph{id est} $x= 0.[0;9]^{19}\|{0}^*$. We set $n=3$ and $\alpha=0.4$. Algorithm \ref{alg:floorstep1} returns $\lfloor x \rfloor_1^\alpha+\frac{1}{2}$ in $24$ iterations.
\end{theorem}
\begin{proof}
  We denote $x + \frac{1}{\pi}\sum_{k=1}^{3}\frac{sin(2\pi k x)}{k}$ by $f(x)$. Let set $(U_n)_{n\in\mathbb{N}}$ such as $U_{n+1} = f(U_n)$. First, we will prove the convergence of $(U_n)_{n\in\mathbb{N}}$. Then, we use the Newton method and a visual proof to demonstrate Theorem \ref{thm:floorstep1}.

  \medskip

  \noindent \textbf{PREUVE DE LA CONVERGENCE A FAIRE!!!!!!}

  \begin{figure}[h!]
    \includegraphics[width =\textwidth]{figure/eqn7Newton.png}
    \caption{Equation \ref{eq:floorfourier} with $n=3$}
    \label{fig:newton3}
  \end{figure}

  For the second part of the proof, we use the Newton method on a graphical representation of $f(x)$(\textcolor{blue}{labeled Eq}). The Newton method, in \textcolor{gray}{grey arrows} in Figure , allows to graphically compute the next term $U_{n+1}$ from $U_n$. We start at the point $(U_n,0)$ ($\num{0.15}$ in this example) and find the point $(U_n,f(U_n))$ (\textcolor{gray}{arrow labeled u}). We then find the point of \textcolor{red}{$c(x)=x$} with ordinate $f(U_n)$ (\textcolor{gray}{arrow labeled v}) and look at its abscissa (\textcolor{gray}{arrow labeled w}), which gives us $U_{n+1}$. Thanks to this method, we can visually compute the number of iterations of Algorithm \ref{alg:floorstep1} required to have $\num{0.46}\leq U_{n+1}\leq \num{0.54}$(\textcolor{green}{green area}). The amount of iterations is shown in Table \ref{tab:n3} (due to the symetric nature of $sin(x)$, we restrict the study on $(0;\num{0.5}]$).

  \begin{table}[!h]
    \caption{Subsets of $(0;\num{0.5}]$ and number of iterations to reach $[\num{0.46};\num{0.54}]$}
    \label{tab:n3}
    \begin{tabularx}{\textwidth}{lcX}
      \toprule
      Number of iterations & &Subsets \\
      \midrule
      1 & &$U_1=[\num{0.0767};\num{0.1002}]\vee[\num{0.1962};\num{0.2522}]\vee[\num{0.3213};\num{0.4060}]\vee [\num{0.4514};\num{0.5}]$\\
      At most 2 & & $U_2=U_1\vee[\num{0.0110};\num{0.0143}]\vee[\num{0.0287};\num{0.0373}]\vee[\num{0.0488};\num{0.0648}]\vee[\num{0.0746};\num{0.263}]\vee[\num{0.3095};\num{0.5}]$\\
      At most 3 & & $U_3=U_2\vee[\num{0.0016};\num{0.002}]\vee[\num{0.0041};\num{0.0052}]\vee[\num{0.007};\num{0.0092}]\vee[\num{0.0107};\num{0.0391}]\vee[\num{0.0469};\num{0.5}]$\\
      \bottomrule
    \end{tabularx}
  \end{table}
\end{proof}

\begin{remark}\label{rem:alpha04}
  The choice of setting $\alpha=\num{0.4}$ in Theorem \ref{thm:floorstep1} is not the most optimal as taking $\alpha=\num{0.5}$ is more advantageous as shown in Proposition \ref{prop:floorbiasopt}. However, by taking $\alpha = \num{0.4}$, we have that Algorithm \ref{alg:floorstep1} returns $\lfloor x \rfloor + err$ such as $\num{0.46}\leq err \leq \num{0.54}$. Thus, by retrieving to this result $0.45$, we have $\num{0.01} \leq err - \num{0.45} \leq \num{0.09}$. By multiplying by $10$, we have $\num{0.1} \leq 10*(err-\num{0.45}) \leq \num{0.9}$. As a result, when applying Algorithm \ref{alg:floorconstruct} we avoid some extreme points and reduce the number of iterations required by Algorithm \ref{alg:floorstep1}. This strategy is not specific to the current set of parameters and will always benefit our method. 
\end{remark}

According to Table \ref{tab:n3}, all values of $x\in[\num{0.1};\num{0.9}]$ converge towards $[\num{0.46};\num{0.54}]$ in less than $3$ iterations. Thus, in accordance with Remark \ref{rem:alpha04} we can limit the number of iterations in the following steps of our floor compuation to only $3$. We can use Algorithm \ref{alg:arfloor} to compute the floor function of $x\in\mathbb{R}\backsim\mathbb{Z}$ in reasonable times.

\begin{algorithm}[H]
  \caption{ArFloor($x,prec$)}
  \label{alg:arfloor}
  \KwData{$x\in\mathbb{R}\backsim\mathbb{Z}$ and the precision $prec\in\mathbb{N}$}
  \KwResult{$\lfloor x \rfloor_prec$}
  $x\leftarrow \emph{ArFloorStep}(x,3,24) -\num{0.45}$\;
  $x \leftarrow 10 \times x$\;
  \For{\texttt{i from 1 to prec-1}}{
    $x \leftarrow \emph{ArFloorStep}(x,3,3) - \num{0.45}$\;
    $x \leftarrow 10 \times x$\;
  }
  \Return{$x \times 10^{-prec}$}
\end{algorithm}

\subsection{Truncation method}

\section{Application to FALCON}\label{sec:appfalcon}
\subsection{Masked Floor Function For FALCON}
\subsection{Masking the Gaussian Sampler}
\section{Performances}\label{sec:perf}

\section{Conclusion}\label{sec:conclusion}
\subsubsection{Acknowlegdments}

%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
 \bibliographystyle{splncs04}
 \bibliography{falcon}

\end{document}
